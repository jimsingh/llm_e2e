{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5982e568-5e5e-4868-a4c1-8e95b51f1e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer and loss\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device) -> float:\n",
    "    input_batch = input_batch.to(device, non_blocking=True)\n",
    "    target_batch = target_batch.to(device, non_blocking=True)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "import math\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        #print(f\"probas.shape: {probas.shape}, \" + str(probas[0, [0, 1, 2]]))\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "        #print(f\"Token Ids:\\n {idx_next} -> {idx}\")\n",
    "    return idx\n",
    "\n",
    "\n",
    "END_OF_TEXT = '<|endoftext|>'\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={END_OF_TEXT})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # (T) -> (B, T)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # (B, T) -> (T)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device) -> float:\n",
    "    input_batch = input_batch.to(device, non_blocking=True)\n",
    "    target_batch = target_batch.to(device, non_blocking=True)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss(loader, model, device, num_batches=None) -> float:\n",
    "    i = 0\n",
    "    total_loss = 0\n",
    "    processed_batches = 0\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(loader):\n",
    "        if i >= num_batches: break\n",
    "\n",
    "        loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "        total_loss += loss\n",
    "        processed_batches += 1\n",
    "\n",
    "    return total_loss / processed_batches\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss(val_loader, model, device, num_batches=eval_iter)\n",
    "\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.position_embeddings.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model=model, idx=encoded, max_new_tokens=20, context_size=context_size)\n",
    "\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(\"decoded text: [\" + decoded_text +\"]\\n\")\n",
    "    model.train()\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer,\n",
    "                start_epoch=0, initial_global_step=-1, initial_tokens_seen=0, initial_best_val_loss=math.inf,\n",
    "                initial_train_losses=None, initial_val_losses=None, initial_track_tokens_seen=None,\n",
    "                checkpoint_path=\"latest_checkpoint.pth\", best_model_path=\"best_model_params.pth\"):\n",
    "\n",
    "    # Initialize from loaded/default states\n",
    "    train_losses = initial_train_losses if initial_train_losses is not None else []\n",
    "    val_losses = initial_val_losses if initial_val_losses is not None else []\n",
    "    track_tokens_seen = initial_track_tokens_seen if initial_track_tokens_seen is not None else []\n",
    "    tokens_seen = initial_tokens_seen\n",
    "    global_step = initial_global_step\n",
    "    best_val_loss = initial_best_val_loss\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            print(\".\", end=\"\")\n",
    "\n",
    "            input_batch = input_batch.to(device, non_blocking=True)\n",
    "            target_batch = target_batch.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # Common max_norm value\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            # xm.mark_step() # xla / tpu\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"epoch {epoch+1} step {global_step:06d}: train loss {train_loss:0.3f}, val loss: {val_loss:0.3f}\")\n",
    "                if val_loss < best_val_loss:\n",
    "                    torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "                    best_val_loss = val_loss\n",
    "                print_sample(model, tokenizer, device, start_context)\n",
    "                save_checkpoint(epoch, global_step, model, optimizer, tokens_seen, best_val_loss,\n",
    "                                train_losses, val_losses, track_tokens_seen, CHECKPOINT_PATH)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "import torch._dynamo\n",
    "import os\n",
    "\n",
    "#os.environ[\"TORCHDYNAMO_VERBOSE\"] = \"1\"\n",
    "#os.environ[\"TORCH_LOGS\"] = \"+dynamo,inductor\" # Get logs from both\n",
    "config['batch_size']=28\n",
    "print(f\"batch size: {config['batch_size']}\")\n",
    "\n",
    "\n",
    "print(\"Creating dataloaders ... \", end=\"\")\n",
    "train_loader = create_dataloader(train_dataset, tokenizer=enc,\n",
    "                                    batch_size=config['batch_size'],\n",
    "                                    max_length=config['context_length'],\n",
    "                                    stride=config['context_length'])\n",
    "\n",
    "val_loader = create_dataloader(val_dataset, tokenizer=enc,\n",
    "                                    batch_size=config['batch_size'],\n",
    "                                    max_length=config['context_length'],\n",
    "                                    stride=config['context_length'])\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "model = GPTModel(config)\n",
    "model.to(device)\n",
    "if device == 'cuda':\n",
    "  model.to(torch.bfloat16)\n",
    "\n",
    "model = torch.compile(model) #, backend='openxla')\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "CHECKPOINT_PATH = '/content/drive/MyDrive/colab/llm_e2e/training_checkpoint.pkl'\n",
    "BEST_MODEL_PATH = '/content/drive/MyDrive/colab/llm_e2e/parameters.pth'\n",
    "#loaded_states = load_checkpoint(CHECKPOINT_PATH, model, optimizer, device)\n",
    "\n",
    "num_epochs=50\n",
    "\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of parameters: {total_params:,}')\n",
    "\n",
    "# --- Start Training ---\n",
    "# Pass the loaded states to train_model\n",
    "train_losses_log, val_losses_log, tokens_seen_log = train_model(\n",
    "    model, overfit_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=1, eval_iter=5,\n",
    "    start_context=\"the fastest way to\", tokenizer=enc,\n",
    "    start_epoch=loaded_states['start_epoch'],\n",
    "    initial_global_step=loaded_states['global_step'],\n",
    "    initial_tokens_seen=loaded_states['tokens_seen'],\n",
    "    initial_best_val_loss=loaded_states['best_val_loss'],\n",
    "    initial_train_losses=loaded_states['train_losses'],\n",
    "    initial_val_losses=loaded_states['val_losses'],\n",
    "    initial_track_tokens_seen=loaded_states['track_tokens_seen'],\n",
    "    checkpoint_path=CHECKPOINT_PATH,\n",
    "    best_model_path=BEST_MODEL_PATH\n",
    ")\n",
    "\n",
    "print(\"Training finished.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e5f906-5761-44e9-85a4-009c8299c200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m145 packages\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m140 packages\u001b[0m \u001b[2min 0.04ms\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimsingh/src/llm_e2e/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m145 packages\u001b[0m \u001b[2min 0.64ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m140 packages\u001b[0m \u001b[2min 0.02ms\u001b[0m\u001b[0m\n",
      "ShakespeareDataloader Initializing: karpathy/tiny_shakespeare with B=2, T=1024, split='train'\n",
      "ShakespeareDataloader Pre-tokenizing text data n=1,003,854 for split 'train'... estimated batches: 147\n",
      "ShakespeareDataloader iterator reset for split 'train', starting at token 0\n",
      "[1,     2] loss: 10.401\n",
      "[1,     4] loss: 9.000\n",
      "[1,     6] loss: 8.250\n",
      "[1,     8] loss: 7.472\n",
      "[1,    10] loss: 6.812\n",
      "[1,    12] loss: 6.420\n",
      "[1,    14] loss: 6.330\n",
      "[1,    16] loss: 6.334\n",
      "[1,    18] loss: 6.507\n",
      "[1,    20] loss: 6.340\n",
      "[1,    22] loss: 6.652\n",
      "[1,    24] loss: 7.109\n",
      "[1,    26] loss: 7.529\n",
      "[1,    28] loss: 7.452\n",
      "[1,    30] loss: 8.287\n",
      "[1,    32] loss: 6.981\n",
      "[1,    34] loss: 6.785\n",
      "[1,    36] loss: 6.492\n",
      "[1,    38] loss: 6.590\n",
      "[1,    40] loss: 6.584\n",
      "[1,    42] loss: 6.820\n",
      "[1,    44] loss: 6.569\n",
      "[1,    46] loss: 6.606\n",
      "[1,    48] loss: 6.715\n",
      "[1,    50] loss: 6.712\n",
      "[1,    52] loss: 6.632\n",
      "[1,    54] loss: 6.543\n",
      "[1,    56] loss: 6.524\n",
      "[1,    58] loss: 6.472\n",
      "[1,    60] loss: 6.310\n",
      "[1,    62] loss: 6.143\n",
      "[1,    64] loss: 6.064\n",
      "[1,    66] loss: 6.467\n",
      "[1,    68] loss: 6.630\n",
      "[1,    70] loss: 6.539\n",
      "[1,    72] loss: 6.446\n",
      "[1,    74] loss: 6.180\n",
      "[1,    76] loss: 6.305\n",
      "[1,    78] loss: 6.098\n",
      "[1,    80] loss: 5.918\n",
      "[1,    82] loss: 6.058\n",
      "[1,    84] loss: 6.142\n",
      "[1,    86] loss: 6.217\n",
      "[1,    88] loss: 6.217\n",
      "[1,    90] loss: 6.358\n",
      "[1,    92] loss: 6.181\n",
      "[1,    94] loss: 6.029\n",
      "[1,    96] loss: 6.038\n",
      "[1,    98] loss: 5.997\n",
      "[1,   100] loss: 5.838\n",
      "[1,   102] loss: 5.926\n",
      "[1,   104] loss: 5.967\n",
      "[1,   106] loss: 6.561\n",
      "[1,   108] loss: 6.445\n",
      "[1,   110] loss: 6.149\n",
      "[1,   112] loss: 6.174\n",
      "[1,   114] loss: 6.534\n",
      "[1,   116] loss: 6.423\n",
      "[1,   118] loss: 6.059\n",
      "[1,   120] loss: 6.130\n",
      "[1,   122] loss: 6.027\n",
      "[1,   124] loss: 6.012\n",
      "[1,   126] loss: 6.332\n",
      "[1,   128] loss: 6.060\n",
      "[1,   130] loss: 5.864\n",
      "[1,   132] loss: 6.034\n",
      "[1,   134] loss: 6.114\n",
      "[1,   136] loss: 5.912\n",
      "[1,   138] loss: 5.820\n",
      "[1,   140] loss: 5.639\n",
      "[1,   142] loss: 5.530\n",
      "[1,   144] loss: 6.376\n",
      "[1,   146] loss: 6.222\n",
      "ShakespeareDataloader No more tokens: __next__: Not enough tokens for a full batch from index 301056. Needed 2048, available: 910 tokens.\n",
      "ShakespeareDataloader iterator reset for split 'train', starting at token 0\n",
      "[2,     2] loss: 6.166\n",
      "[2,     4] loss: 6.070\n",
      "[2,     6] loss: 6.056\n",
      "[2,     8] loss: 5.985\n",
      "[2,    10] loss: 5.687\n",
      "[2,    12] loss: 5.467\n",
      "[2,    14] loss: 5.508\n",
      "[2,    16] loss: 5.514\n",
      "[2,    18] loss: 5.612\n",
      "[2,    20] loss: 5.512\n",
      "[2,    22] loss: 5.743\n",
      "[2,    24] loss: 5.936\n",
      "[2,    26] loss: 6.119\n",
      "[2,    28] loss: 5.988\n",
      "[2,    30] loss: 5.780\n",
      "[2,    32] loss: 5.717\n",
      "[2,    34] loss: 5.506\n",
      "[2,    36] loss: 5.420\n",
      "[2,    38] loss: 5.616\n",
      "[2,    40] loss: 5.458\n",
      "[2,    42] loss: 5.746\n",
      "[2,    44] loss: 5.383\n",
      "[2,    46] loss: 5.723\n",
      "[2,    48] loss: 5.847\n",
      "[2,    50] loss: 5.983\n",
      "[2,    52] loss: 5.874\n",
      "[2,    54] loss: 5.789\n",
      "[2,    56] loss: 5.786\n",
      "[2,    58] loss: 5.729\n",
      "[2,    60] loss: 5.635\n",
      "[2,    62] loss: 5.469\n",
      "[2,    64] loss: 5.344\n",
      "[2,    66] loss: 5.704\n",
      "[2,    68] loss: 5.858\n",
      "[2,    70] loss: 5.849\n",
      "[2,    72] loss: 5.742\n",
      "[2,    74] loss: 5.480\n",
      "[2,    76] loss: 5.642\n",
      "[2,    78] loss: 5.496\n",
      "[2,    80] loss: 5.327\n",
      "[2,    82] loss: 5.451\n",
      "[2,    84] loss: 5.580\n",
      "[2,    86] loss: 5.563\n",
      "[2,    88] loss: 5.592\n",
      "[2,    90] loss: 5.769\n",
      "[2,    92] loss: 5.574\n",
      "[2,    94] loss: 5.416\n",
      "[2,    96] loss: 5.428\n",
      "[2,    98] loss: 5.412\n",
      "[2,   100] loss: 5.254\n",
      "[2,   102] loss: 5.372\n",
      "[2,   104] loss: 5.363\n",
      "[2,   106] loss: 5.939\n",
      "[2,   108] loss: 5.756\n",
      "[2,   110] loss: 5.558\n",
      "[2,   112] loss: 5.593\n",
      "[2,   114] loss: 6.010\n",
      "[2,   116] loss: 5.859\n",
      "[2,   118] loss: 5.490\n",
      "[2,   120] loss: 5.524\n",
      "[2,   122] loss: 5.524\n",
      "[2,   124] loss: 5.448\n",
      "[2,   126] loss: 5.573\n",
      "[2,   128] loss: 5.287\n",
      "[2,   130] loss: 5.222\n",
      "[2,   132] loss: 5.371\n",
      "[2,   134] loss: 5.395\n",
      "[2,   136] loss: 5.304\n",
      "[2,   138] loss: 5.247\n",
      "[2,   140] loss: 5.099\n",
      "[2,   142] loss: 5.002\n",
      "[2,   144] loss: 5.858\n",
      "[2,   146] loss: 5.660\n",
      "ShakespeareDataloader No more tokens: __next__: Not enough tokens for a full batch from index 301056. Needed 2048, available: 910 tokens.\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade tiktoken datasets fsspec\n",
    "import torch\n",
    "import tiktoken\n",
    "import itertools\n",
    "\n",
    "def estimate_loss(model, loader, device, eval_iters):\n",
    "    model.eval()\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    for i, (X, Y) in enumerate(itertools.islice(loader, eval_iters)):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        logits, loss = model(X, Y)\n",
    "        losses[i] = loss.item()\n",
    "    model.train()\n",
    "    return losses.mean()\n",
    "\n",
    "@torch.no_grad\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iters):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      model: to evaluate\n",
    "      train_loader: training dataset iterator\n",
    "      val_loader: validation dataset iterator\n",
    "      eval_iters: the number of iterations to pull from the loaders\n",
    "  \n",
    "    Returns:\n",
    "      dict with 'train' and 'val' loss \n",
    "  \"\"\"\n",
    "    train_loss = estimate_loss(model, train_loader, device, eval_iters)\n",
    "    val_loss = estimate_loss(model, val_loader, device, eval_iters)\n",
    "    return {'train': train_loss, 'val': val_loss}\n",
    "    \n",
    "def train_model(model, train_loader, val_loader, optimizer, cfg):\n",
    "    device = torch.device(cfg.device)\n",
    "    \n",
    "    for epoch in range(cfg.num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for i, (X, Y) in enumerate(train_loader):\n",
    "            X, Y = X.to(cfg.device), Y.to(cfg.device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # forward + backward + optimize\n",
    "            logits, loss = model(X, Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if (i + 1) % cfg.log_iterval == 0:\n",
    "                print(f\"[{epoch + 1}  {i + 1:5d}]: running loss {running_loss / cfg.log_iterval:.3f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "            if (i + 1) % cfg.eval_interval == 0:\n",
    "                losses = evaluate_model(model, train_loader, val_loader, device, eval_iters=cfg.eval_iters)\n",
    "                print(f\"[{epoch + 1}  {i + 1:5d}]: train loss: {losses['train']:.4f}, val loss: {losses['val']:.4f}, eval_iters: {cfg.eval_iters}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "cfg = GPT2Config() #.from_yaml(\"gpt2_config.yaml\")\n",
    "gpt2 = tiktoken.get_encoding('gpt2')\n",
    "tokenizer = lambda r: {'tokens': gpt2.encode_batch(r['text'], allowed_special={\"<|endoftext|>\"})} # endoftext may separate documents\n",
    "\n",
    "train_loader = ShakespeareDataloader(batch_size=cfg.batch_size, sequence_length=cfg.context_length, tokenizer=tokenizer)\n",
    "val_loader = ShakespeareDataloader(batch_size=cfg.batch_size, sequence_length=cfg.context_length, tokenizer=tokenizer, split='test')\n",
    "\n",
    "model = GPTModel(cfg)\n",
    "model.to(cfg.device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.learning_rate, weight_decay=cfg.weight_decay)\n",
    "train_model(model, train_loader, val_loader, optimizer, cfg=cfg)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cefc52b-523d-41ac-be91-a47eaeab9ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: 'First Citizen'\n",
      "Original token IDs: [[5962, 22307]]\n",
      "Predicted token IDs: [[198, 11]]\n",
      "Decoded output: ['\\n,']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Assuming tokenizer, model, and gpt2 (tiktoken encoding) are defined and on the CPU.\n",
    "\n",
    "test = \"First Citizen\"\n",
    "\n",
    "# Tokenize\n",
    "# tkns will be like [[id1, id2, ...]]\n",
    "tokenized_output = tokenizer({'text': [test]})\n",
    "tkns_list_of_lists = tokenized_output['tokens']\n",
    "\n",
    "# Convert to tensor (already on CPU by assumption)\n",
    "input_ids = torch.tensor(tkns_list_of_lists, dtype=torch.long)\n",
    "\n",
    "# Model inference\n",
    "with torch.no_grad(): # Disable gradient calculations for inference\n",
    "    # Assuming model(input_ids) returns (logits, ...) or just logits\n",
    "    # If model directly returns logits: model_output = model(input_ids)\n",
    "    # If model returns a tuple (logits, other_outputs): model_output = model(input_ids)[0]\n",
    "    # The original code had [0], so we'll keep that structure, assuming logits are the first element.\n",
    "    logits = model(input_ids)[0] # Logits shape: (batch_size, sequence_length, vocab_size)\n",
    "\n",
    "# Convert logits to predicted token IDs\n",
    "# predicted_token_ids shape: (batch_size, sequence_length)\n",
    "predicted_token_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "# Decode the predicted token IDs\n",
    "# gpt2.decode_batch expects a list of lists of integers.\n",
    "decoded_texts = gpt2.decode_batch(predicted_token_ids.tolist())\n",
    "\n",
    "print(f\"Input text: '{test}'\")\n",
    "print(f\"Original token IDs: {tkns_list_of_lists}\")\n",
    "print(f\"Predicted token IDs: {predicted_token_ids.tolist()}\")\n",
    "print(f\"Decoded output: {decoded_texts}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
