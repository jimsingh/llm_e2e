{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad511bae-86d5-4b9d-a0ac-bed20db8e160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m145 packages\u001b[0m \u001b[2min 0.58ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m140 packages\u001b[0m \u001b[2min 0.02ms\u001b[0m\u001b[0m\n",
      "ShakespeareDataloader Initializing: karpathy/tiny_shakespeare with B=5, T=1024, split='train'\n",
      "ShakespeareDataloader Pre-tokenizing text data n=1,003,854 for split 'train'... estimated batches: 58\n",
      "ShakespeareDataloader iterator reset for split 'train', starting at token 0\n",
      "Total tokens analyzed: 102,400\n",
      "Unique tokens: 7013\n",
      "Top 10 tokens:\n",
      "  ID 198   ('\\n'      ): 12,382 (0.1209)\n",
      "  ID 11    (','       ): 5,909  (0.0577)\n",
      "  ID 25    (':'       ): 3,139  (0.0307)\n",
      "  ID 13    ('.'       ): 2,362  (0.0231)\n",
      "  ID 262   (' the'    ): 1,753  (0.0171)\n",
      "  ID 284   (' to'     ): 1,298  (0.0127)\n",
      "  ID 286   (' of'     ): 1,090  (0.0106)\n",
      "  ID 290   (' and'    ): 1,083  (0.0106)\n",
      "  ID 26    (';'       ): 1,003  (0.0098)\n",
      "  ID 314   (' I'      ): 997    (0.0097)\n",
      "Vocabulary coverage: 0.13954275026364488\n",
      "ShakespeareDataloader iterator reset for split 'train', starting at token 0\n",
      "x: [5962, 22307, 25, 198, 8421, 356, 5120, 597, 2252, 11, 3285, 502, 2740, 13, 198]\n",
      "y: [22307, 25, 198, 8421, 356, 5120, 597, 2252, 11, 3285, 502, 2740, 13, 198, 198]\n",
      "x: 'First Citizen:\\nBefore we proceed any further, hear me speak.\\n'\n",
      "y: ' Citizen:\\nBefore we proceed any further, hear me speak.\\n\\n'\n",
      "x: [514, 13, 198, 198, 49275, 1677, 40, 2937, 25, 198, 32478, 345, 1276, 198, 18546]\n",
      "y: [13, 198, 198, 49275, 1677, 40, 2937, 25, 198, 32478, 345, 1276, 198, 18546, 408]\n",
      "x: ' us.\\n\\nMENENIUS:\\nEither you must\\nConf'\n",
      "y: '.\\n\\nMENENIUS:\\nEither you must\\nConfess'\n",
      "\u001b[2mResolved \u001b[1m145 packages\u001b[0m \u001b[2min 0.59ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m140 packages\u001b[0m \u001b[2min 0.02ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%run -n 00_config.ipynb\n",
    "%run -n 01_data_pipeline.ipynb\n",
    "%run -n 02_gpt2_model.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6e5f906-5761-44e9-85a4-009c8299c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def estimate_loss(model, loader, device, eval_iters):\n",
    "    model.eval()\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    for i, (X, Y) in enumerate(itertools.islice(loader, eval_iters)):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        logits, loss = model(X, Y)\n",
    "        losses[i] = loss.item()\n",
    "    model.train()\n",
    "    return losses.mean()\n",
    "\n",
    "@torch.no_grad\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iters):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      model: to evaluate\n",
    "      train_loader: training dataset iterator\n",
    "      val_loader: validation dataset iterator\n",
    "      eval_iters: the number of iterations to pull from the loaders\n",
    "\n",
    "    Returns:\n",
    "      dict with 'train' and 'val' loss\n",
    "  \"\"\"\n",
    "    train_loss = estimate_loss(model, train_loader, device, eval_iters)\n",
    "    val_loss = estimate_loss(model, val_loader, device, eval_iters)\n",
    "    return {'train': train_loss, 'val': val_loss}\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, cfg):\n",
    "    device = torch.device(cfg.device) # Ensure device object\n",
    "\n",
    "    if device.type == 'cuda':\n",
    "        print(\"Starting training on CUDA device. Initializing memory stats.\")\n",
    "        # Reset peak stats at the beginning of training if you want to track peaks per training run\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "        print_gpu_memory_stats(\"Start of training_model\", device)\n",
    "\n",
    "    for epoch in range(cfg.num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        print(f\"[{epoch + 1} / {cfg.num_epochs}]: starting at {datetime.now()}, will log runnig loss every {cfg.log_interval} steps, will eval every {cfg.eval_interval} steps\")\n",
    "        if device.type == 'cuda':\n",
    "            print_gpu_memory_stats(f\"Start of Epoch {epoch + 1}\", device)\n",
    "\n",
    "        for i, (X, Y) in enumerate(train_loader):\n",
    "            X, Y = X.to(cfg.device), Y.to(cfg.device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            logits, loss = model(X, Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if (i + 1) % cfg.log_interval == 0:\n",
    "                print(f\"[{epoch + 1}  {i + 1:5d}]: running loss {running_loss / cfg.log_interval:.3f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "            if (i + 1) % cfg.eval_interval == 0:\n",
    "                losses = evaluate_model(model, train_loader, val_loader, device, eval_iters=cfg.eval_iters)\n",
    "                print(f\"[{epoch + 1}  {i + 1:5d}]: train loss: {losses['train']:.4f}, val loss: {losses['val']:.4f}, eval_iters: {cfg.eval_iters}\")\n",
    "                running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cefc52b-523d-41ac-be91-a47eaeab9ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 / 2]: starting at 2025-06-02 22:07:04.362767, will log every 10 steps\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GPT2Config' object has no attribute 'log_iterval'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m     model = torch.compile(model)\n\u001b[32m     22\u001b[39m optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.learning_rate, weight_decay=cfg.weight_decay)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mFinished Training\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, cfg)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# print statistics\u001b[39;00m\n\u001b[32m     61\u001b[39m running_loss += loss.item()\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (i + \u001b[32m1\u001b[39m) % \u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_iterval\u001b[49m == \u001b[32m0\u001b[39m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m5d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]: running loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39mcfg.log_interval\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     64\u001b[39m     running_loss = \u001b[32m0.0\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: 'GPT2Config' object has no attribute 'log_iterval'"
     ]
    }
   ],
   "source": [
    "cfg = GPT2Config().from_yaml(\"gpt2_config.yaml\")\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "train_loader = GeneratorWrapper(cfg, enc)\n",
    "val_loader = GeneratorWrapper(cfg, enc)\n",
    "\n",
    "try:\n",
    "  del model\n",
    "except:\n",
    "  pass\n",
    "\n",
    "try:\n",
    "  del optimizer\n",
    "except:\n",
    "  pass\n",
    "\n",
    "model = GPTModel(cfg)\n",
    "model.to(cfg.device)\n",
    "if cfg.compile_model:\n",
    "    model = torch.compile(model)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.learning_rate, weight_decay=cfg.weight_decay)\n",
    "train_model(model, train_loader, val_loader, optimizer, cfg=cfg)\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
