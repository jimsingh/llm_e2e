data:
    dataset_path: 'rahular/simple-wikipedia'
    dataset_name: 'default'
    block_size: 1024

model:
    vocab_size: 50257 # gpt2 vocab
    context_length: 256
    emb_dim: int = 384
    n_heads: int = 2
    n_layers: int = 2
    dropout_rate: float = 0.1
    qkv_bias: bool = False
    mlp_bias: bool = True
    
training:
    batch_size: 2
    log_interval: 10
    eval_iters: 10
    eval_interval: 50

system:
    device: cpu