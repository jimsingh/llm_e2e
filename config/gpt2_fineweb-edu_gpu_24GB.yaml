data:
    dataset_path: 'HuggingFaceFW/fineweb-edu'
    dataset_name: 'sample-10BT'
    block_size: 1024

model:
    vocab_size: 50304 # gpt2 vocab word aligneed
    context_length: 384 
    emb_dim: 384
    n_heads: 8
    n_layers: 8
    dropout_rate: 0.02
    qkv_bias: False
    mlp_bias: True

training:
    num_epochs: 1
    learning_rate: 0.009
    batch_size: 108 
    log_interval: 300
    eval_iters: 30
    eval_interval: 1500
    save_interval: 1500

logging:
  wandb_log: True

system:
    device: cuda 
